{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep/Feature Eng\n",
    "* use cross val for tuning and selecting hyperparameters\n",
    "* use test set at very end on best model\n",
    "* find optimal complexityq to balance bias variance\n",
    "\n",
    "### TRY ALL MODELS - but have rationale on why you are trying models\n",
    "* document the iterative process\n",
    "\n",
    "### Deliverables\n",
    "* Contract by monday 2pm mountain time - communication frequency and tangible deadlines\n",
    "* model completed by monday EOD\n",
    "* proof of concept that your target and predictors are fit for machine learning classification\n",
    "* decide as a team if target can be used as is or needs to be transformed\n",
    "* FSM\n",
    "\n",
    "### GROUP: Evan, Drew, Mustafa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var = pd.read_csv('data/training_set_features.csv')\n",
    "df_tar = pd.read_csv('data/training_set_labels.csv')['seasonal_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Based On Relevance\n",
    "df_var = df_var.drop(['respondent_id','h1n1_concern','h1n1_knowledge','opinion_h1n1_vacc_effective','opinion_h1n1_risk','opinion_h1n1_sick_from_vacc','doctor_recc_h1n1','hhs_geo_region'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_nan = df_var.isna().sum() / df_var.shape[0] * 100\n",
    "percent_nan.map(round)[percent_nan > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop based on Nan\n",
    "df_var = df_var.drop(['health_insurance','income_poverty','employment_industry','employment_occupation'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df_var,df_tar,random_state=42)\n",
    "X_train = X_train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_columns = ['behavioral_antiviral_meds', \n",
    "                    'behavioral_avoidance',\n",
    "                    'behavioral_face_mask', \n",
    "                    'behavioral_wash_hands',\n",
    "                    'behavioral_large_gatherings', \n",
    "                    'behavioral_outside_home',\n",
    "                    'behavioral_touch_face', \n",
    "                    'doctor_recc_seasonal',\n",
    "                    'chronic_med_condition', \n",
    "                    'child_under_6_months', \n",
    "                    'health_worker',\n",
    "                    'education', \n",
    "                    'rent_or_own', \n",
    "                    'marital_status', \n",
    "                    'employment_status',\n",
    "                    'sex']\n",
    "                                                     \n",
    "median_columns = ['opinion_seas_vacc_effective', \n",
    "                  'opinion_seas_risk',\n",
    "                  'opinion_seas_sick_from_vacc',\n",
    "                  'household_adults', \n",
    "                  'household_children']\n",
    "\n",
    "ohe_cols = ['opinion_seas_vacc_effective', \n",
    "            'opinion_seas_risk',\n",
    "            'opinion_seas_sick_from_vacc',\n",
    "            'age_group','education',\n",
    "            'race',\n",
    "            'employment_status', \n",
    "            'census_msa']\n",
    "\n",
    "oe_cols = ['sex','marital_status','rent_or_own']\n",
    "\n",
    "non_imputed_cols = ['age_group', 'race', 'census_msa']\n",
    "\n",
    "# Ordinal Encoding\n",
    "# Sex - 0=Female | 1=Male\n",
    "# Marital Status - 0=Married | 1=Not Married\n",
    "# Rent or Own - 0=Own | 1=Rent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute certain columns with ColumnTransformer\n",
    "col_imputer = ColumnTransformer(transformers=[\n",
    "    (\"sim\", SimpleImputer(strategy='most_frequent'), frequent_columns),\n",
    "    (\"sib\", SimpleImputer(strategy='median'), median_columns)\n",
    "    ],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "#OrdinalEncode and OneHotEncode certain columns with ColumnTransformer\n",
    "col_oe_ohe = ColumnTransformer(transformers=[\n",
    "    ('oe', OrdinalEncoder(categories='auto'), oe_cols),\n",
    "    (\"ohe\", OneHotEncoder(categories=\"auto\", drop='first'), ohe_cols)\n",
    "    ], \n",
    "    remainder='passthrough')\n",
    "\n",
    "# Create a pipeline containing the impute ColumnTransformer\n",
    "impute_pipe = Pipeline(steps=[\n",
    "    ('col_imputer', col_imputer)\n",
    "])\n",
    "\n",
    "#Fit and transform X_train through impute pipeline\n",
    "imputed = impute_pipe.fit_transform(X_train)\n",
    "\n",
    "#Create new dataframe with newly imputed data\n",
    "X_train_pipe_impute = pd.DataFrame(imputed, columns=frequent_columns + median_columns + non_imputed_cols)\n",
    "\n",
    "\n",
    "#Create a pipeline containing the encoding ColumnTransformer\n",
    "encode_scale_pipe = Pipeline(steps=[\n",
    "    ('col_oe_ohe', col_oe_ohe),\n",
    "    ('ss', StandardScaler())\n",
    "])\n",
    "\n",
    "#Fit and transform imputed data through encode pipeline\n",
    "transformed_data = encode_scale_pipe.fit_transform(X_train_pipe_impute)\n",
    "\n",
    "#Isolate and create feature names of the OneHotEncoded features\n",
    "encoder = col_oe_ohe.named_transformers_['ohe']\n",
    "category_labels = encoder.get_feature_names(ohe_cols)\n",
    "\n",
    "# Make a dataframe with the transformed data\n",
    "X_train_pipe_processed = pd.DataFrame(transformed_data, columns=oe_cols + list(category_labels) + list(X_train_pipe_impute.drop(ohe_cols + oe_cols, axis=1).columns))\n",
    "X_train_pipe_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_clf = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gbt_clf.fit(X_train_pipe_processed, y_train)\n",
    "gbt_clf.score(X_train_pipe_processed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     'loss': ['deviance', 'exponential'],\n",
    "#     'learning_rate': [.1, .01, .001],\n",
    "#     'n_estimators': [10, 50, 100],\n",
    "#     'max_depth': [None, 2, 3],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 3]\n",
    "# }\n",
    "\n",
    "# gs_tree = GridSearchCV(gbt_clf, grid, cv=3, return_train_score=True)\n",
    "# gs_tree.fit(X_train_pipe_processed, np.ravel(y_train))\n",
    "\n",
    "\n",
    "# gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'loss': ['deviance', 'exponential'],\n",
    "    'learning_rate': [.1, .01, .001],\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "\n",
    "#'min_samples_leaf': [1, 2, 3]\n",
    "\n",
    "gs_tree = GridSearchCV(gbt_clf, grid, cv=3, return_train_score=True)\n",
    "gs_tree.fit(X_train_pipe_processed, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_tree.best_params_\n",
    "\n",
    "gbt_clf = GradientBoostingClassifier(random_state=42, learning_rate=.1, loss='exponential', min_samples_split=5)\n",
    "\n",
    "gbt_clf.fit(X_train_pipe_processed, np.ravel(y_train))\n",
    "gbt_clf.score(X_train_pipe_processed, np.ravel(y_train))\n",
    "y_pred = gbt_clf.predict(X_train_pipe_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "cross_val = cross_val_score(gbt_clf, X_train_pipe_processed, np.ravel(y_train), scoring='accuracy', cv=3)\n",
    "cross_val.mean()\n",
    "\n",
    "auc_score = roc_auc_score(y_train, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_test = impute_pipe.transform(X_test)\n",
    "\n",
    "#Create new dataframe with newly imputed data\n",
    "X_test_pipe_impute = pd.DataFrame(imputed_test, columns=frequent_columns + median_columns + non_imputed_cols)\n",
    "\n",
    "transformed_test_data = encode_scale_pipe.transform(X_test_pipe_impute)\n",
    "\n",
    "X_test_pipe_processed = pd.DataFrame(transformed_test_data, columns=oe_cols + list(category_labels) + list(X_test_pipe_impute.drop(ohe_cols + oe_cols, axis=1).columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_cv_rfe = []\n",
    "gb_keep_lists = []\n",
    "max_features = 20\n",
    "for n in range(1,max_features+1):\n",
    "    num_features_to_select = n\n",
    "    gb_rfe = GradientBoostingClassifier(random_state=42, learning_rate=.1, loss='exponential', min_samples_split=5)\n",
    "    select = RFE(gb_rfe, n_features_to_select=num_features_to_select)\n",
    "    select.fit(X=X_train_pipe_processed, y=y_train)\n",
    "    feature_list = [(k,v) for k,v in zip(X_train_pipe_processed.columns,select.support_)]\n",
    "    current_keep_list = []\n",
    "    for k,v in feature_list:\n",
    "        if v:\n",
    "            current_keep_list.append(k)\n",
    "    \n",
    "    current_cv = cross_val_score(gb_rfe,X_train_pipe_processed[current_keep_list],y_train,cv=3,scoring='roc_auc').mean()\n",
    "\n",
    "    gb_cv_rfe.append(current_cv)\n",
    "    gb_keep_lists.append(current_keep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "ax.plot(range(1,max_features+1),gb_cv_rfe)\n",
    "ax.set_xlabel('Number of Features')\n",
    "ax.set_ylabel('Mean Cross Val ROC AUC Score for Decision Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_final = GradientBoostingClassifier(random_state=42, learning_rate=.1, loss='exponential', min_samples_split=5)\n",
    "gb_final.fit(X_train_pipe_processed[gb_keep_lists[19]], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, gb_final.predict(X_test_pipe_processed[gb_keep_lists[19]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(gb_final,X_train_pipe_processed[gb_keep_lists[19]],y_train,cv=5,scoring='roc_auc').mean()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c94be41889154d41bf43aca8d1a8d1cd64b97c119170e03e2ed46ca87183f0c5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
