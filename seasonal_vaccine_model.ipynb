{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Vaccination Likelyhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "In light of their new vaccination initiative, the CDC has conducted surveys on random individuals throughout the country. Deliver a predictive binary classifier model to stakeholder (CDC) that determines if someone will take the Seasonal Flu vaccine based on responses to a phone survey. Predictions on future surveys can help assess public health risk by determining the percent of the population likely to get vaccinated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix,plot_confusion_matrix, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var = pd.read_csv('data/training_set_features.csv')\n",
    "df_tar = pd.read_csv('data/training_set_labels.csv')['seasonal_vaccine']\n",
    "df_var = df_var.drop(['respondent_id','h1n1_concern','h1n1_knowledge','opinion_h1n1_vacc_effective','opinion_h1n1_risk','opinion_h1n1_sick_from_vacc','doctor_recc_h1n1','hhs_geo_region'],axis=1)\n",
    "df_var = df_var.drop(['health_insurance','income_poverty','employment_industry','employment_occupation'],axis=1)\n",
    "X_train,X_test,y_train,y_test = train_test_split(df_var,df_tar,random_state=42)\n",
    "X_train = X_train.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frequent_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-41543801c5b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m col_imputer = ColumnTransformer(transformers=[\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"sim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'most_frequent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrequent_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"sib\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'median'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmedian_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frequent_columns' is not defined"
     ]
    }
   ],
   "source": [
    "col_imputer = ColumnTransformer(transformers=[\n",
    "    (\"sim\", SimpleImputer(strategy='most_frequent'), frequent_columns),\n",
    "\n",
    "    (\"sib\", SimpleImputer(strategy='median'), median_columns)\n",
    "\n",
    "    ],\n",
    "    remainder=\"passthrough\")\n",
    "\n",
    "col_ohe = ColumnTransformer(transformers=[\n",
    "    (\"ohe\", OneHotEncoder(categories=\"auto\", drop='first'), ohe_cols)\n",
    "    ], \n",
    "    remainder='passthrough')\n",
    "# Create a pipeline containing the single column transformer\n",
    "\n",
    "pipe1 = Pipeline(steps=[\n",
    "    ('col_imputer', col_imputer)\n",
    "])\n",
    "\n",
    "imputed = pipe1.fit_transform(X_train)\n",
    "X_train_pipe_impute = pd.DataFrame(imputed, columns=X_train.columns)\n",
    "\n",
    "pipe2 = Pipeline(steps=[\n",
    "    ('col_ohe', col_ohe)\n",
    "])\n",
    "\n",
    "# Use the pipeline to fit and transform the data\n",
    "transformed_data = pipe2.fit_transform(X_train)\n",
    "\n",
    "encoder = col_ohe.namedtransformers['ohe']\n",
    "category_labels = encoder.get_feature_names(ohe_columns)\n",
    "\n",
    "# Make a dataframe with the relevant columns\n",
    "X_train_pipe_processed = pd.DataFrame(transformed_data, columns=list(X_train_pipe_impute.drop(ohe_columns, axis=1).columns) + list(category_labels))\n",
    "X_train_pipe_processed.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model - Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Classifier\n",
    "dc = DummyClassifier(strategy='most_frequent',random_state=42)\n",
    "dc.fit(X_train_ohe_scaled,y_train)\n",
    "cv_scores = cross_val_score(dc,X_train_ohe_scaled,y_train,cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridsearch on Logreg Lasso Penalty\n",
    "\n",
    "logreg_l1 = LogisticRegression()\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.linspace(1e-5,1,50),\n",
    "    'solver': ['liblinear','saga'],\n",
    "    'penalty': ['l1']\n",
    "}\n",
    "\n",
    "gs_logreg_l1 = GridSearchCV(logreg_l1, param_grid, cv=3)\n",
    "gs_logreg_l1.fit(X_train_ohe_scaled, y_train)\n",
    "\n",
    "gs_logreg_l1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Feature Selection\n",
    "\n",
    "cv_rfe = []\n",
    "keep_lists = []\n",
    "max_features = 20\n",
    "for n in range(1,max_features+1):\n",
    "    num_features_to_select = n\n",
    "    lr_rfe = LogisticRegression(penalty='l1',random_state=42,solver='liblinear')\n",
    "    select = RFE(lr_rfe, n_features_to_select=num_features_to_select)\n",
    "    select.fit(X=X_train_ohe_scaled, y=y_train)\n",
    "    feature_list = [(k,v) for k,v in zip(X_train_ohe_scaled.columns,select.support_)]\n",
    "    current_keep_list = []\n",
    "    for k,v in feature_list:\n",
    "        if v:\n",
    "            current_keep_list.append(k)\n",
    "    \n",
    "    current_cv = cross_val_score(lr_rfe,X_train_ohe[current_keep_list],y_train,cv=3,scoring='roc_auc').mean()\n",
    "\n",
    "    cv_rfe.append(current_cv)\n",
    "    keep_lists.append(current_keep_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Mean Cross Val AUC ROC for RFE Models\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "ax.plot(range(1,max_features+1),cv_rfe)\n",
    "ax.set_xlabel('Number of Features')\n",
    "ax.set_ylabel('Mean Cross Val ROC AUC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix of Final Logreg Model\n",
    "\n",
    "plot_confusion_matrix(logreg_final,X_train_ohe_scaled[keep_lists[-1]],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Logreg Model Mean Cross Val AUC ROC Score\n",
    "\n",
    "logreg_final = LogisticRegression(penalty='l1',random_state=42,solver='saga',C = 0.08164183673469387)\n",
    "logreg_final.fit(X_train_ohe_scaled[keep_lists[-1]],y_train)\n",
    "cross_val_score(lr_rfe,X_train_ohe[keep_lists[-1]],y_train,cv=5,scoring='roc_auc').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conlclusion"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a3d059f376a9d0551670ac739dcc834dd342b8d7d90019c6bdbef463e084516"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
